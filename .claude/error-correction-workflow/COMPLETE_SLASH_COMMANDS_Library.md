# CUSTOM SLASH COMMANDS - PART 2

## Tier 2, 3, 4, Final Commands and Special Commands

**Continuation of Command Library**  
**Version:** 2.0  
**Last Updated:** October 29, 2025

---

## /phase-3-tier-2

```dart
/phase-3-tier-2

Execute Phase 3 - Tier 2: Error & Dependency Fixes

PRE-TIER CHECKLIST:
✓ Tier 1 validation complete (or caution)
✓ Phase 2 task list available
✓ All ERR-* and DEP-* tasks identified
✓ Codebase-Composer ready

TIER 2 EXECUTION:

STEP 1: IDENTIFY ERROR & DEPENDENCY TASKS
Extract all ERR-* (error) and DEP-* (dependency) tasks:
- Total error tasks: [X]
- Total dependency tasks: [X]
- Critical priority: [X]
- High priority: [X]

---

STEP 2: INVOKE CODEBASE-COMPOSER FOR TIER 2
Agent: codebase-composer
Priority: CRITICAL
Model: opus

Instruction:
"codebase-composer: Orchestrate and execute Tier 2 error and dependency fixes.

TIER 2 TASKS (ERROR & DEPENDENCY):
[Insert all ERR-* and DEP-* tasks]
[Include: errors from Phase 1, dependencies from Phase 2]

ERROR & DEPENDENCY FIX ORCHESTRATION:

STEP 1: TASK SEQUENCING
├─ Analyze all error and dependency tasks
├─ Identify dependencies between tasks
├─ Sequence for optimal implementation
├─ Plan for minimal rework

STEP 2: ERROR RESOLUTION (Priority 1)
Execute error resolution tasks in order:
├─ Null pointer fixes
├─ Type mismatch corrections
├─ Logic error fixes
├─ Exception handling improvements
├─ Resource management fixes

For each error task:
├─ Implement the fix
├─ Verify error disappears
├─ Test the fix works
├─ Ensure no regressions
├─ Document change

STEP 3: DEPENDENCY RESOLUTION (Priority 2)
Execute dependency resolution tasks:
├─ Update version conflicts
├─ Resolve circular dependencies
├─ Fix missing dependencies
├─ Update deprecated packages
├─ Ensure compatibility

For each dependency task:
├─ Update to compatible version
├─ Run dependency checks
├─ Verify resolution works
├─ Test integration
├─ Document version update

STEP 4: INTEGRATION VERIFICATION
├─ Verify errors no longer occur
├─ Check dependencies all resolve
├─ Test system runs without errors
├─ Validate no new errors introduced
├─ Confirm no regressions

STEP 5: DOCUMENTATION
├─ Document all fixes made
├─ List error resolutions
├─ List dependency updates
├─ Provide testing summary
├─ Update architecture docs

DELIVERABLE:
Generate comprehensive Tier 2 report:
- Error tasks completed: X/[Total]
- Dependency tasks completed: X/[Total]
- Errors fixed and verified
- Dependencies updated and tested
- Files modified list
- Integration testing results
- Status: COMPLETE / ISSUES

OUTPUT: Save as reports/phase_3_tier2_implementation.md

Execute tier 2 error and dependency fixes now."

---

STEP 3: TIER 2 COMPLETION
After implementation completes:

Display:
"✅ Tier 2 (Error & Dependency Fixes) Execution Complete

Implementation Report: reports/phase_3_tier2_implementation.md
Error Tasks: [X/Total] completed
Dependency Tasks: [X/Total] completed

Improvements Made:
- Error count reduced: X → 0
- Dependency conflicts: X resolved
- System now runs error-free

Ready for Validation Gate 3B

Next Command: /phase-3-tier-2-validate"

END COMMAND
```

---

## /phase-3-tier-2-validate

```dart
/phase-3-tier-2-validate

Execute Validation Gate 3B: Tier 2 Error & Dependency Verification

---

STEP 1: KAREN ASSESSMENT
Agent: karen-reality-manager
Model: sonnet

Instruction:
"karen-reality-manager: Verify Tier 2 error and dependency fixes work.

TIER 2 IMPLEMENTATION:
[Insert Tier 2 Implementation Report]

REALITY CHECK:

Question 1: Error Fixes Actually Work?
- Do fixed errors actually disappear when code runs?
- Are edge cases properly handled?
- Fixes sustainable and robust?
- No latent errors remaining?
Response: [Verification]

Question 2: Dependencies Actually Resolved?
- Do dependencies all install correctly?
- Are conflicts genuinely resolved?
- No transitive dependency issues?
- Compatible versions selected?
Response: [Verification]

Question 3: System Stable & Runnable?
- Does system run without errors?
- Build succeeds without warnings?
- Performance acceptable?
- Stability improved?
Response: [Verification]

Question 4: Backward Compatibility?
- Existing code still works?
- No breaking changes introduced?
- Migration smooth if versions updated?
Response: [Verification]

Question 5: Production Ready?
- Error-free enough for production?
- Dependency versions stable?
- Ready for deployment?
Response: [Verification]

DECISION: PASS / CAUTION / REWORK

=== KAREN'S VERIFICATION (Gate 3B) ===
[Complete verification]
DECISION: [PASS / CAUTION / REWORK]
=== END ==="

Save to: reports/gate_3b_karen_verification.md

---

STEP 2: Jenny ASSESSMENT
Agent: Jenny-spec-auditor
Model: opus

Instruction:
"Jenny-spec-auditor: Verify Tier 2 specification compliance.

TIER 2 IMPLEMENTATION:
[Insert Tier 2 Implementation Report]

COMPLIANCE AUDIT:

Question 1: All Errors Fixed?
- Were all identified errors resolved?
- Every error addressed?
- No errors left unfixed?
Response: [Audit]

Question 2: All Dependencies Resolved?
- All conflicts resolved?
- All versions updated as specified?
- All dependencies consistent?
Response: [Audit]

Question 3: Solutions Technically Sound?
- Fixes architecturally correct?
- Dependency versions compatible?
- No architectural debt introduced?
Response: [Audit]

Question 4: Testing Complete?
- Error fixes tested?
- Dependency updates tested?
- Integration testing done?
Response: [Audit]

Question 5: Documentation Complete?
- Changes documented?
- Error fixes recorded?
- Dependency updates recorded?
Response: [Audit]

DECISION: PASS / CONCERN / FAIL

=== Jenny'S AUDIT (Gate 3B) ===
[Complete audit]
DECISION: [PASS / CONCERN / FAIL]
=== END ==="

Save to: reports/gate_3b_Jenny_audit.md

---

STEP 3: DECISION
If approved:
"✅ VALIDATION GATE 3B PASSED

Ready for Tier 3: Optimization & Refactoring

Next Command: /phase-3-tier-3"

If issues:
"[STATUS] VALIDATION GATE 3B [RESULT]

[Next action based on result]"

END COMMAND
```

---

## /phase-3-tier-3

```dart
/phase-3-tier-3

Execute Phase 3 - Tier 3: Optimization & Refactoring

PRE-TIER CHECKLIST:
✓ Tier 2 validation complete
✓ All PERF-* (performance) and REF-* (refactoring) tasks identified
✓ Codebase-Composer ready

TIER 3 EXECUTION:

STEP 1: EXTRACT OPTIMIZATION & REFACTORING TASKS
- Total performance tasks: [X]
- Total refactoring tasks: [X]

---

STEP 2: INVOKE CODEBASE-COMPOSER FOR TIER 3
Agent: codebase-composer
Priority: HIGH
Model: opus

Instruction:
"codebase-composer: Orchestrate Tier 3 optimization and refactoring.

TIER 3 TASKS (PERFORMANCE & REFACTORING):
[Insert all PERF-* and REF-* tasks]

OPTIMIZATION & REFACTORING ORCHESTRATION:

STEP 1: PERFORMANCE OPTIMIZATION (Priority 1)
Execute performance improvements:
├─ Implement algorithmic optimizations
├─ Resolve memory leaks
├─ Eliminate bottlenecks
├─ Optimize data structures
├─ Implement caching
├─ Fix N+1 patterns

For each optimization:
├─ Implement improvement
├─ Measure performance gain
├─ Test correctness
├─ Document improvement
├─ Verify no regressions

STEP 2: CODE REFACTORING (Priority 2)
Execute refactoring improvements:
├─ Apply design patterns
├─ Eliminate code duplication
├─ Decompose large functions
├─ Improve architecture
├─ Enhance readability
├─ Update documentation

For each refactoring:
├─ Implement refactoring
├─ Maintain functionality
├─ Test thoroughly
├─ Verify no breaking changes
├─ Document changes

STEP 3: VERIFICATION
├─ Performance improvements verified
├─ Refactored code works correctly
├─ No functionality lost
├─ No new issues introduced
├─ Codebase quality improved

STEP 4: DOCUMENTATION
├─ Document optimizations made
├─ Explain design pattern implementations
├─ Record performance improvements
├─ Update architecture documentation

DELIVERABLE:
Generate comprehensive Tier 3 report:
- Performance tasks: X/[Total] completed
- Refactoring tasks: X/[Total] completed
- Performance improvements made
- Design patterns implemented
- Code quality metrics improved
- Files refactored
- Status: COMPLETE / ISSUES

OUTPUT: Save as reports/phase_3_tier3_implementation.md

Execute tier 3 optimization and refactoring now."

---

STEP 3: TIER 3 COMPLETION
Display:
"✅ Tier 3 (Optimization & Refactoring) Execution Complete

Implementation Report: reports/phase_3_tier3_implementation.md
Performance Tasks: [X/Total]
Refactoring Tasks: [X/Total]

Improvements:
- Performance optimized: [metrics]
- Design patterns: X implemented
- Code duplication: [X%] reduced
- Codebase quality: [improved]

Ready for Validation Gate 3C

Next Command: /phase-3-tier-3-validate"

END COMMAND
```

---

## /phase-3-tier-3-validate

```dart
/phase-3-tier-3-validate

Execute Validation Gate 3C: Tier 3 Optimization & Refactoring Verification

---

STEP 1: KAREN ASSESSMENT
Agent: karen-reality-manager
Model: sonnet

Instruction:
"karen-reality-manager: Verify Tier 3 optimizations work in practice.

TIER 3 IMPLEMENTATION:
[Insert Tier 3 Implementation Report]

REALITY CHECK:

Question 1: Performance Improvements Real?
- Are optimizations measurably faster?
- Performance gains significant?
- Can be measured and verified?
Response: [Verification]

Question 2: Refactored Code Maintainable?
- Is refactored code easy to understand?
- Better than original?
- Can developers work with it?
Response: [Verification]

Question 3: Backward Compatibility?
- Does refactored code maintain behavior?
- All functionality still works?
- No breaking changes?
Response: [Verification]

Question 4: No Performance Regressions?
- Performance not degraded elsewhere?
- No new bottlenecks created?
- Overall system faster?
Response: [Verification]

Question 5: Production Deployment Ready?
- Refactored code stable?
- Ready for production?
- Acceptable quality?
Response: [Verification]

DECISION: PASS / CAUTION / REWORK

=== KAREN'S VERIFICATION (Gate 3C) ===
[Complete verification]
DECISION: [PASS / CAUTION / REWORK]
=== END ==="

Save to: reports/gate_3c_karen_verification.md

---

STEP 2: Jenny ASSESSMENT
Agent: Jenny-spec-auditor
Model: opus

Instruction:
"Jenny-spec-auditor: Verify Tier 3 specification compliance.

TIER 3 IMPLEMENTATION:
[Insert Tier 3 Implementation Report]

COMPLIANCE AUDIT:

Question 1: All Optimizations Implemented?
- All PERF-* tasks completed?
- Every optimization addressed?
Response: [Audit]

Question 2: All Refactoring Completed?
- All REF-* tasks implemented?
- Every refactoring done?
Response: [Audit]

Question 3: Quality Standards Met?
- Code meets quality standards?
- Design patterns properly implemented?
- Architecture improved?
Response: [Audit]

Question 4: Testing Complete?
- Performance improvements tested?
- Refactored code tested?
- Integration tested?
Response: [Audit]

Question 5: Documentation Complete?
- Optimizations documented?
- Refactoring documented?
- Design decisions recorded?
Response: [Audit]

DECISION: PASS / CONCERN / FAIL

=== Jenny'S AUDIT (Gate 3C) ===
[Complete audit]
DECISION: [PASS / CONCERN / FAIL]
=== END ==="

Save to: reports/gate_3c_Jenny_audit.md

---

STEP 3: DECISION
If approved:
"✅ VALIDATION GATE 3C PASSED

Ready for Tier 4: Standards & Cleanup

Next Command: /phase-3-tier-4"

END COMMAND
```

---

## /phase-3-tier-4

```dart
/phase-3-tier-4

Execute Phase 3 - Tier 4: Standards & Cleanup

PRE-TIER CHECKLIST:
✓ Tier 3 validation complete
✓ All STD-* (standards) and CLN-* (cleanup) tasks identified
✓ Codebase-Composer ready

TIER 4 EXECUTION:

STEP 1: EXTRACT STANDARDS & CLEANUP TASKS
- Total standards tasks: [X]
- Total cleanup tasks: [X]

---

STEP 2: INVOKE CODEBASE-COMPOSER FOR TIER 4
Agent: codebase-composer
Priority: MEDIUM
Model: opus

Instruction:
"codebase-composer: Orchestrate Tier 4 standards and cleanup.

TIER 4 TASKS (STANDARDS & CLEANUP):
[Insert all STD-* and CLN-* tasks]

STANDARDS & CLEANUP ORCHESTRATION:

STEP 1: STANDARDS ENFORCEMENT (Priority 1)
Apply all code standards:
├─ Fix naming inconsistencies
├─ Correct formatting violations
├─ Update comments and documentation
├─ Apply linting standards
├─ Enforce consistent patterns

For each standards task:
├─ Identify violations
├─ Apply corrections
├─ Verify standards met
├─ Run linting tools
├─ Document changes

STEP 2: DEAD CODE REMOVAL (Priority 2)
Remove all dead code:
├─ Delete unused imports
├─ Remove unused functions
├─ Delete unused variables
├─ Remove dead branches
├─ Clean up obsolete code

For each cleanup task:
├─ Verify safe to remove
├─ Remove the code
├─ Test nothing breaks
├─ Verify removal complete
├─ Document removal

STEP 3: FINAL VERIFICATION
├─ All standards applied
├─ Dead code completely removed
├─ Codebase clean and consistent
├─ No obvious quality issues remaining

STEP 4: DOCUMENTATION
├─ Document standards applied
├─ Record dead code removed
├─ Update codebase documentation
├─ Final cleanup summary

DELIVERABLE:
Generate comprehensive Tier 4 report:
- Standards tasks: X/[Total] completed
- Cleanup tasks: X/[Total] completed
- Standards compliance: [%]
- Dead code removed: X items
- Files cleaned
- Status: COMPLETE

OUTPUT: Save as reports/phase_3_tier4_implementation.md

Execute tier 4 standards and cleanup now."

---

STEP 3: TIER 4 COMPLETION
Display:
"✅ Tier 4 (Standards & Cleanup) Execution Complete

Implementation Report: reports/phase_3_tier4_implementation.md
Standards Tasks: [X/Total]
Cleanup Tasks: [X/Total]

Codebase State:
- Standards compliance: [%]
- Dead code removed: X items
- Codebase quality: [Excellent/Good/Acceptable]

All Phase 3 Tiers Complete!

Ready for Validation Gate 3D (Final Tier Approval)

Next Command: /phase-3-tier-4-validate"

END COMMAND
```

---

## /phase-3-tier-4-validate

```dart
/phase-3-tier-4-validate

Execute Validation Gate 3D: Tier 4 Standards & Cleanup Verification

---

STEP 1: KAREN ASSESSMENT
Agent: karen-reality-manager
Model: sonnet

Instruction:
"karen-reality-manager: Verify Tier 4 cleanup is production-ready.

TIER 4 IMPLEMENTATION:
[Insert Tier 4 Implementation Report]

REALITY CHECK:

Question 1: Codebase Production Ready?
- Is codebase truly production-ready?
- Are there any remaining blockers?
- Acceptable quality for deployment?
Response: [Verification]

Question 2: Standards Applied?
- Are standards actually applied everywhere?
- Consistent and complete?
- No exceptions or gaps?
Response: [Verification]

Question 3: Dead Code Removed?
- Is dead code completely removed?
- Nothing left that shouldn't be there?
- Cleanup thorough?
Response: [Verification]

Question 4: System Stable?
- Does system run without issues?
- Performance stable?
- No new problems from cleanup?
Response: [Verification]

Question 5: Ready for Phase 4 Testing?
- Ready for comprehensive testing?
- All prerequisites met?
- Deployment ready?
Response: [Verification]

DECISION: PASS / CAUTION / REWORK

=== KAREN'S VERIFICATION (Gate 3D) ===
[Complete verification]
DECISION: [PASS / CAUTION / REWORK]
=== END ==="

Save to: reports/gate_3d_karen_verification.md

---

STEP 2: Jenny ASSESSMENT
Agent: Jenny-spec-auditor
Model: opus

Instruction:
"Jenny-spec-auditor: Verify Tier 4 specification compliance.

TIER 4 IMPLEMENTATION:
[Insert Tier 4 Implementation Report]

COMPLIANCE AUDIT:

Question 1: All Standards Applied?
- All STD-* tasks completed?
- Standards met everywhere?
- Compliance 100%?
Response: [Audit]

Question 2: All Dead Code Removed?
- All CLN-* tasks completed?
- Dead code completely removed?
- Inventory cleared?
Response: [Audit]

Question 3: Documentation Complete?
- All documentation updated?
- Comments adequate?
- Records accurate?
Response: [Audit]

Question 4: Quality Standards Met?
- Code quality acceptable?
- Standards compliance satisfied?
- Specifications met?
Response: [Audit]

Question 5: Final Verification?
- Everything production-ready?
- All requirements satisfied?
- Approval to proceed to Phase 4?
Response: [Audit]

DECISION: PASS / CONCERN / FAIL

=== Jenny'S AUDIT (Gate 3D) ===
[Complete audit]
DECISION: [PASS / CONCERN / FAIL]
=== END ==="

Save to: reports/gate_3d_Jenny_audit.md

---

STEP 3: DECISION
If approved:
"✅ VALIDATION GATE 3D PASSED

All Phase 3 Tiers COMPLETE and VALIDATED

Phase 3 Summary:
- Tier 1: Security Hardening ✅
- Tier 2: Error & Dependency Fixes ✅
- Tier 3: Optimization & Refactoring ✅
- Tier 4: Standards & Cleanup ✅

Ready for Phase 4: Final Validation & Delivery

Next Command: /phase-4"

END COMMAND
```

---

## /phase-4

```dart
/phase-4

Execute Phase 4: Final Validation & Delivery

PRE-PHASE CHECKLIST:
✓ All Phase 3 tiers complete and validated
✓ Complete implemented codebase ready
✓ testing-and-validation-specialist ready
✓ Reports directory prepared

PHASE 4 EXECUTION:

STEP 1: INVOKE TESTING-AND-VALIDATION-SPECIALIST
Agent: testing-and-validation-specialist
Priority: CRITICAL
Model: opus

Instruction:
"testing-and-validation-specialist: Conduct comprehensive final testing and validation.

COMPLETE IMPLEMENTATION CONTEXT:
[Insert all Phase 3 implementation reports]
[Codebase with all Tier 1-4 changes applied]

COMPREHENSIVE TESTING REQUIREMENTS:

STEP 1: UNIT TESTING
├─ Test all modified functions and methods
├─ Edge cases and boundary conditions
├─ Error handling paths
├─ New functionality

STEP 2: INTEGRATION TESTING
├─ Cross-module functionality
├─ API contracts validated
├─ Database interactions
├─ External service calls
├─ Tier-to-tier integration

STEP 3: SECURITY TESTING
├─ Verify security fixes work
├─ Confirm vulnerabilities eliminated
├─ No new security issues
├─ Access control validation
├─ Data protection verification

STEP 4: PERFORMANCE TESTING
├─ Measure optimization improvements
├─ Verify performance gains achieved
├─ No performance regressions
├─ Load testing if applicable
├─ Memory profiling

STEP 5: REGRESSION TESTING
├─ Existing functionality intact
├─ No breaking changes
├─ Backward compatibility maintained
├─ Previous functionality works

STEP 6: END-TO-END TESTING
├─ Complete workflows tested
├─ User scenarios verified
├─ System behaves correctly
├─ All requirements met

DELIVERABLE:
Generate comprehensive testing report:
- Test plan executed: [description]
- Total tests run: X
- Tests passed: X
- Tests failed: 0
- Test coverage: [%]
- Issues found: [list if any]
- Performance metrics: [measurements]
- Security validation: [results]
- Regression test results: [results]
- Overall test result: PASS / FAIL

OUTPUT: Save as reports/phase_4_testing_report.md

Execute comprehensive testing now."

---

STEP 2: DOCUMENTATION REVIEW & UPDATE
Verify and update all documentation:
├─ API documentation updated
├─ Architecture documentation current
├─ Deployment procedures documented
├─ Rollback procedures documented
├─ Configuration documented
├─ Change log updated
└─ Release notes prepared

---

STEP 3: PHASE 4 COMPLETION
After testing completes:

Display:
"✅ Phase 4 (Final Validation & Testing) Execution Complete

Testing Report: reports/phase_4_testing_report.md

Testing Results:
- Total tests: X
- Passed: X
- Failed: 0
- Coverage: [%]
- Status: PASS / FAIL

Security Validation: [Confirmed/Issues]
Performance Improvements: [Verified/Not met]
Regression Testing: [No regressions/Issues]

Ready for Final Approval Gate

Next Command: /phase-4-validate"

END COMMAND
```

---

## /phase-4-validate

```dart
/phase-4-validate

Execute Final Validation Gate: Production Approval

---

STEP 1: KAREN ASSESSMENT
Agent: karen-reality-manager
Model: sonnet

Instruction:
"karen-reality-manager: Final production readiness assessment.

COMPLETE WORKFLOW RESULTS:
[Insert all Phase 3 and Phase 4 reports]
[Insert testing report]

FINAL REALITY CHECK:

Question 1: System Production Ready?
- Is system truly ready for production?
- All major issues resolved?
- Acceptable risk level?
Response: [Assessment]

Question 2: Overall System Health?
- System stable and performant?
- No known critical issues?
- Can handle production load?
Response: [Assessment]

Question 3: Deployment Readiness?
- Deployment procedures ready?
- Rollback plan prepared?
- Team ready to deploy?
Response: [Assessment]

Question 4: Post-Deployment Support?
- Support team prepared?
- Documentation ready?
- Monitoring in place?
Response: [Assessment]

Question 5: Final Recommendation?
- Recommend production deployment? Yes/No
- Any final concerns?
- Conditions for deployment?
Response: [Assessment]

FINAL DECISION: APPROVE / APPROVE WITH CONDITIONS / REJECT

=== KAREN'S FINAL ASSESSMENT ===
[Complete assessment]
FINAL DECISION: [APPROVE/CONDITIONS/REJECT]
=== END ==="

Save to: reports/final_karen_approval.md

---

STEP 2: Jenny ASSESSMENT
Agent: Jenny-spec-auditor
Model: opus

Instruction:
"Jenny-spec-auditor: Final specification compliance verification.

COMPLETE WORKFLOW RESULTS:
[Insert all reports]

FINAL COMPLIANCE VERIFICATION:

Question 1: ALL Issues Resolved?
- Every issue from Phase 1 addressed?
- 100% completion?
Response: [Verification]

Question 2: All Tasks Completed?
- Every task from Phase 2 executed?
- Nothing left unfinished?
Response: [Verification]

Question 3: Quality Standards Met?
- Code meets all quality standards?
- Zero issues with specifications?
Response: [Verification]

Question 4: Testing Complete?
- Comprehensive testing done?
- All scenarios covered?
Response: [Verification]

Question 5: Final Specification Compliance?
- Deliverable meets all specifications?
- All requirements satisfied?
- Production-grade quality?
Response: [Verification]

FINAL DECISION: APPROVE / APPROVE WITH CONDITIONS / REJECT

=== Jenny'S FINAL VERIFICATION ===
[Complete verification]
FINAL DECISION: [APPROVE/CONDITIONS/REJECT]
=== END ==="

Save to: reports/final_Jenny_approval.md

---

STEP 3: MASTER REPORT GENERATION
After both approvals:

/generate-master-report

END COMMAND
```

---

## /generate-master-report

```dart
/generate-master-report

Generate Comprehensive Master Error Elimination Report

EXECUTIVE SUMMARY SECTION:
Create Master Report File: reports/master_error_elimination_report.md

Format:
# MASTER ERROR ELIMINATION REPORT

## EXECUTIVE SUMMARY
- Workflow completion date: [timestamp]
- Total workflow duration: [X hours]
- Issues identified: [X total]
- Issues resolved: [X total]
- Test coverage: [X%]
- Final status: COMPLETE

## WORKFLOW OVERVIEW

### Phase Progression
- Phase 1: Initial Threat Assessment ✅
- Phase 2: Relational Analysis & Task Generation ✅
- Phase 3: Implementation Execution (4 Tiers) ✅
- Phase 4: Final Validation & Testing ✅

### Validation Gates
- Gate 1 (Phase 1): ✅ PASSED
- Gate 2 (Phase 2): ✅ PASSED
- Gate 3A (Tier 1): ✅ PASSED
- Gate 3B (Tier 2): ✅ PASSED
- Gate 3C (Tier 3): ✅ PASSED
- Gate 3D (Tier 4): ✅ PASSED
- Final Gate: ✅ APPROVED

## ISSUES BY SEVERITY

### Critical (Total: X, Resolved: X)
[List each with resolution summary]

### High (Total: X, Resolved: X)
[List each with resolution summary]

### Medium (Total: X, Resolved: X)
[List each with resolution summary]

### Low (Total: X, Resolved: X)
[List each with resolution summary]

## ISSUES BY CATEGORY

### Security (X identified, X resolved)
[Summary of security improvements]

### Errors & Exceptions (X identified, X resolved)
[Summary of error fixes]

### Performance (X identified, X resolved)
[Summary of performance improvements]

### Code Quality (X identified, X resolved)
[Summary of quality improvements]

### Dead Code (X identified, X resolved)
[Summary of dead code removed]

### Standards (X identified, X resolved)
[Summary of standards applied]

## IMPLEMENTATION SUMMARY

### Tier 1: Security Hardening
- Duration: [X hours]
- Tasks completed: X/X
- Security vulnerabilities fixed: X
- Status: ✅ COMPLETE

### Tier 2: Error & Dependency Fixes
- Duration: [X hours]
- Tasks completed: X/X
- Errors fixed: X
- Dependencies updated: X
- Status: ✅ COMPLETE

### Tier 3: Optimization & Refactoring
- Duration: [X hours]
- Tasks completed: X/X
- Performance improvements: X
- Code duplications eliminated: X
- Design patterns implemented: X
- Status: ✅ COMPLETE

### Tier 4: Standards & Cleanup
- Duration: [X hours]
- Tasks completed: X/X
- Standards applied: X
- Dead code items removed: X
- Status: ✅ COMPLETE

## QUALITY METRICS

### Test Coverage
- Unit test coverage: [X%]
- Integration test coverage: [X%]
- Overall coverage: [X%]
- Tests passed: X/X
- Tests failed: 0

### Performance Improvements
- Average speed improvement: [X%]
- Memory optimization: [X%]
- Database query improvement: [X%]

### Security Status
- Vulnerabilities identified: X
- Vulnerabilities resolved: X
- Security score: [X/10]

### Code Quality
- Code duplication: [X% reduced]
- Standards compliance: [X%]
- Dead code: [0 items remaining]
- Architecture: [Good/Excellent]

## VALIDATION RESULTS

### Karen Assessment (Reality Manager)
- Overall feasibility score: [X/10]
- Risk assessment: [Low/Medium/High]
- Final recommendation: APPROVE

### Jenny Assessment (Spec Auditor)
- Specification compliance: [X%]
- Completeness: [X%]
- Quality standards: [X/10]
- Final recommendation: APPROVE

## RECOMMENDATIONS & NEXT STEPS

### Immediate Actions
[Any urgent items before deployment]

### Deployment Checklist
- [ ] Backup production systems
- [ ] Deploy changes
- [ ] Run smoke tests
- [ ] Monitor system
- [ ] Verify improvements

### Follow-up Items
[Ongoing improvements recommended for future]

### Post-Deployment Monitoring
[Metrics to track after deployment]

## APPENDIX: DETAILED REPORTS

All detailed phase reports available:
- Phase 1 Report: reports/phase_1_report.md
- Phase 2 Report: reports/phase_2_report.md
- Phase 3 Tier 1 Report: reports/phase_3_tier1_implementation.md
- Phase 3 Tier 2 Report: reports/phase_3_tier2_implementation.md
- Phase 3 Tier 3 Report: reports/phase_3_tier3_implementation.md
- Phase 3 Tier 4 Report: reports/phase_3_tier4_implementation.md
- Phase 4 Testing Report: reports/phase_4_testing_report.md

---

Display Final Summary:
"
╔═══════════════════════════════════════════════════════════╗
║     ERROR ELIMINATION WORKFLOW - COMPLETE SUCCESS! ✅     ║
╚═══════════════════════════════════════════════════════════╝

MASTER REPORT GENERATED: reports/master_error_elimination_report.md

WORKFLOW STATISTICS:
├─ Total duration: [X hours]
├─ Phases completed: 4/4 ✅
├─ Validation gates passed: 7/7 ✅
├─ Issues identified: X
├─ Issues resolved: X (100%)
├─ Test coverage: X%
└─ Final status: PRODUCTION READY ✅

APPROVALS:
├─ Karen (Reality Manager): ✅ APPROVED
└─ Jenny (Spec Auditor): ✅ APPROVED

DELIVERABLES:
✅ Master Error Elimination Report
✅ Complete implementation documentation
✅ Test reports and results
✅ Deployment-ready codebase
✅ All recommendations

Ready for production deployment!

Thank you for using the Error Elimination Workflow.
"

END COMMAND
```

---

## SPECIAL COMMANDS

### /validation-gate

```dart
/validation-gate

Generic validation gate command for manual assessment

Usage: /validation-gate [gate_number] [context]

Example:
/validation-gate 1 [Paste Phase 1 Report]

Invokes Karen and Jenny for assessment of any phase/tier.

Invoke both Karen and Jenny with assessment prompts.
Generate combined decision.
Return PASS / CAUTION / REWORK decision.
```

### /rework

```dart
/rework

Handle rework scenarios for failed validation gates

Usage: /rework [phase] [issues_to_fix]

Steps:
1. Identify root cause of failure
2. Classify as: Implementation Error / Design Issue / Specification Gap
3. Generate corrective actions
4. Execute rework
5. Re-validate

Cannot skip to next phase until rework resolved.
```

### /workflow-status

```dart
/workflow-status

Get current workflow state and progress

Displays:
- Current phase: [1-4]
- Current tier: [if Phase 3]
- Status: [INITIALIZED / IN PROGRESS / COMPLETE / BLOCKED]
- Completed tasks: [%]
- Validation gates passed: [X/7]
- Next steps: [Commands to execute]
- Any blockers: [Issues preventing progress]

Use to check progress anytime during workflow.
```

### /escalate

```dart
/escalate

Escalate issue to Error Eliminator Commander

Use when:
- Karen and Jenny cannot agree
- Validation gates repeatedly failing
- Major blocker preventing progress
- Need workflow commander arbitration

Escalates to Error Eliminator for final decision.
```

---

- **End of Part 2 - Complete Slash Command Library Ready for Use**
